name: Livelo Partners Scraper
on:
  schedule:
    - cron: '0 12 * * *'  # Executa todos os dias às 12:00 UTC
  workflow_dispatch:  # Permite execução manual
permissions:
  contents: write
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout do repositório
        uses: actions/checkout@v4
        
      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Configurar Chrome
        uses: browser-actions/setup-chrome@latest
        
      - name: Instalar dependências
        run: |
          pip install selenium webdriver-manager pandas openpyxl selenium-stealth undetected-chromedriver plotly numpy
          # Verificar versão do Selenium e ChromeDriver
          python -c "import selenium; print(f'Selenium version: {selenium.__version__}')"
          python -c "from webdriver_manager.chrome import ChromeDriverManager; print(f'ChromeDriver path: {ChromeDriverManager().install()}')"
          
      - name: Verificar ambiente
        run: |
          echo "Diretório atual: $(pwd)"
          echo "Conteúdo do diretório: $(ls -la)"
          echo "Versão do Chrome: $(chrome --version)"
          
      - name: Criar diretórios para logs e saída
        run: |
          mkdir -p logs
          mkdir -p relatorios
          
      - name: Executar scraper diretamente (para depuração)
        run: |
          python livelo_scraper.py 2>&1 | tee scraper_debug.log
        continue-on-error: true
          
      - name: Executar script principal
        run: |
          python main.py 2>&1 | tee output.log
        continue-on-error: true
        
      - name: Upload de arquivos de diagnóstico
        uses: actions/upload-artifact@v3
        with:
          name: debug-files
          path: |
            *.html
            *.png
            *.txt
            *.log
          retention-days: 3
        
      - name: Verificar falhas na execução
        run: |
          if cat output.log | grep -q "Falha no scraper\|Falha no reporter\|ERRO FATAL"; then
            echo "::warning::Falhas detectadas na execução!"
            grep -A 10 "Falha\|ERRO" output.log || true
            echo "SCRAPING_FALHOU=true" >> $GITHUB_ENV
          else
            echo "Nenhuma falha detectada na execução."
          fi
      
      - name: Configurar Git para commit
        run: |
          git config --local user.email "actions@github.com"
          git config --local user.name "GitHub Actions"
          
      - name: Commit e push dos novos dados
        run: |
          # Copiar logs
          if [ -f "output.log" ]; then
            cp output.log logs/scraper_$(date +%Y%m%d_%H%M%S).log
          fi
          
          # Adicionar todos os arquivos relevantes mesmo se houver falhas
          # Isso permite ver os arquivos de diagnóstico no repositório
          git add -f *.html *.png *.txt *.log || echo "Nenhum arquivo de diagnóstico para adicionar"
          git add logs/
          git add relatorios/ || echo "Pasta relatorios não existe"
          
          # Tentar adicionar o arquivo Excel se existir
          git add livelo_parceiros.xlsx || echo "Arquivo Excel não encontrado"
          
          # Tentar adicionar o relatório HTML se existir
          git add relatorio_livelo.html || echo "Arquivo HTML não encontrado"
          
          git commit -m "Atualização automática e arquivos de diagnóstico [$(date)]" || echo "Sem alterações para commit"
          git push || echo "Falha ao fazer push, continuando mesmo assim"
