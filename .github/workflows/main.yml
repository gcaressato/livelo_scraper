name: Livelo Partners Scraper
on:
  schedule:
    - cron: '0 12 * * *'  # Executa todos os dias √†s 12:00 UTC
  workflow_dispatch:  # Permite execu√ß√£o manual
permissions:
  contents: write
  pages: write
  id-token: write
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout do reposit√≥rio
        uses: actions/checkout@v4
        
      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Configurar Chrome
        uses: browser-actions/setup-chrome@latest
        
      - name: Instalar depend√™ncias
        run: |
          pip install selenium webdriver-manager pandas openpyxl selenium-stealth plotly numpy
          # Verificar vers√£o do Selenium e Chrome
          python -c "import selenium; print(f'Selenium version: {selenium.__version__}')"
          google-chrome --version
          
      - name: Verificar ambiente
        run: |
          echo "Diret√≥rio atual: $(pwd)"
          echo "Conte√∫do do diret√≥rio: $(ls -la)"
          
      - name: Criar diret√≥rios para logs e sa√≠da
        run: |
          mkdir -p logs
          mkdir -p relatorios
          
      - name: Executar scraper diretamente (para depura√ß√£o)
        run: |
          python livelo_scraper.py 2>&1 | tee scraper_debug.log
        continue-on-error: true
          
      - name: Executar script principal
        run: |
          python main.py 2>&1 | tee output.log
        continue-on-error: true
        
      # NOVA ETAPA: VALIDA√á√ÉO INTELIGENTE DE DADOS
      - name: Validar qualidade dos dados
        id: validate
        run: |
          python -c "
          import pandas as pd
          from datetime import datetime, timedelta
          import os
          
          success = True
          
          try:
              # Verificar se arquivo Excel existe
              if not os.path.exists('livelo_parceiros.xlsx'):
                  print('‚ùå Arquivo Excel n√£o encontrado!')
                  success = False
              else:
                  df = pd.read_excel('livelo_parceiros.xlsx')
                  
                  # Verificar se dados s√£o recentes (√∫ltimas 24h)
                  df['Timestamp'] = pd.to_datetime(df['Timestamp'])
                  latest_date = df['Timestamp'].max()
                  now = datetime.now()
                  
                  if (now - latest_date).total_seconds() > 86400:  # 24 horas
                      print(f'‚ö†Ô∏è Dados podem estar antigos! √öltimo: {latest_date}')
                  
                  # Verificar quantidade m√≠nima
                  if len(df) < 30:
                      print(f'‚ö†Ô∏è Poucos dados coletados: {len(df)} registros')
                  else:
                      print(f'‚úÖ Dados validados: {len(df)} registros, √∫ltimo em {latest_date}')
              
              # Verificar se HTML foi gerado
              if not os.path.exists('relatorio_livelo.html'):
                  print('‚ùå HTML n√£o foi gerado!')
                  success = False
              else:
                  print('‚úÖ HTML gerado com sucesso')
              
              if success:
                  print('VALIDATION_SUCCESS=true')
              else:
                  print('VALIDATION_FAILED=true')
                  
          except Exception as e:
              print(f'‚ùå Erro na valida√ß√£o: {e}')
              print('VALIDATION_ERROR=true')
          " 2>&1 | tee validation.log
        continue-on-error: true
        
      - name: Verificar falhas na execu√ß√£o
        run: |
          if cat output.log | grep -q "Falha no scraper\|Falha no reporter\|ERRO FATAL"; then
            echo "::warning::Falhas detectadas na execu√ß√£o!"
            grep -A 10 "Falha\|ERRO" output.log || true
            echo "SCRAPING_FALHOU=true" >> $GITHUB_ENV
          else
            echo "Nenhuma falha detectada na execu√ß√£o."
            echo "SCRAPING_FALHOU=false" >> $GITHUB_ENV
          fi
      
      # NOVA ETAPA: CRIAR ISSUE AUTOM√ÅTICA SE FALHOU
      - name: Criar issue se scraper falhou
        if: env.SCRAPING_FALHOU == 'true'
        uses: actions/github-script@v6
        with:
          script: |
            const title = `üö® Scraper falhou em ${new Date().toLocaleString('pt-BR')}`;
            const body = `
            ## ‚ùå Falha no Scraper Livelo
            
            **‚è∞ Hor√°rio:** ${new Date().toLocaleString('pt-BR', {timeZone: 'America/Sao_Paulo'})}
            **üîó Logs:** [Ver detalhes](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            
            ### Poss√≠veis causas:
            - [ ] Site mudou estrutura HTML
            - [ ] Elementos foram alterados  
            - [ ] Timeout de conex√£o
            - [ ] Erro no processamento dos dados
            
            ### ‚ö†Ô∏è A√ß√£o necess√°ria:
            1. Verificar logs do workflow
            2. Testar scraper localmente
            3. Ajustar seletores se necess√°rio
            4. Fechar esta issue ap√≥s corre√ß√£o
            
            ---
            *Issue criada automaticamente pelo GitHub Actions*
            `;
            
            // Verificar se j√° existe issue aberta
            const existingIssues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'scraper-failure'
            });
            
            if (existingIssues.data.length === 0) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['scraper-failure', 'urgent']
              });
              
              console.log('üìß Issue criada - voc√™ receber√° email do GitHub automaticamente!');
            } else {
              console.log('Issue de falha j√° existe, n√£o criando duplicata');
            }
      
      - name: Listar arquivos de diagn√≥stico
        run: |
          echo "Arquivos HTML gerados:"
          ls -la *.html || echo "Nenhum arquivo HTML encontrado"
          echo "Arquivos de log gerados:"
          ls -la *.log || echo "Nenhum arquivo de log encontrado"
          echo "Screenshots gerados:"
          ls -la *.png || echo "Nenhum screenshot encontrado"
      
      - name: Configurar Git para commit
        run: |
          git config --local user.email "actions@github.com"
          git config --local user.name "GitHub Actions"
          
      - name: Commit e push dos novos dados
        run: |
          # Copiar logs
          if [ -f "output.log" ]; then
            cp output.log logs/scraper_$(date +%Y%m%d_%H%M%S).log
          fi
          
          # Adicionar arquivos de diagn√≥stico individualmente para evitar problemas
          for file in debug_*.html debug_*.png debug_*.txt *.log; do
            if [ -f "$file" ]; then
              git add -f "$file" || echo "N√£o foi poss√≠vel adicionar $file"
            fi
          done
          
          # Adicionar diret√≥rios
          if [ -d "logs" ]; then
            git add logs/ || echo "N√£o foi poss√≠vel adicionar logs/"
          fi
          
          if [ -d "relatorios" ]; then
            git add relatorios/ || echo "N√£o foi poss√≠vel adicionar relatorios/"
          fi
          
          # Adicionar o arquivo Excel se existir
          if [ -f "livelo_parceiros.xlsx" ]; then
            git add livelo_parceiros.xlsx || echo "N√£o foi poss√≠vel adicionar livelo_parceiros.xlsx"
          fi
          
          # Adicionar o relat√≥rio HTML se existir
          if [ -f "relatorio_livelo.html" ]; then
            git add relatorio_livelo.html || echo "N√£o foi poss√≠vel adicionar relatorio_livelo.html"
          fi
          
          # Tentar commit com verifica√ß√£o se h√° algo para comitar
          git diff --staged --quiet || git commit -m "Atualiza√ß√£o autom√°tica [$(date)]"
          
          # Push com tratamento de erro
          git push || echo "Falha ao fazer push, verifique os logs para mais detalhes"
      
      # ============ SE√á√ÉO PWA + FIREBASE ============
      
      - name: Setup Node.js para Firebase
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Criar arquivos PWA
        run: |
          # Criar manifest.json
          cat > manifest.json << 'EOF'
          {
            "name": "Livelo Analytics Pro",
            "short_name": "Livelo",
            "description": "Dashboard anal√≠tico para ofertas Livelo",
            "start_url": "/",
            "display": "standalone",
            "background_color": "#151f4f",
            "theme_color": "#ff0a8c",
            "orientation": "portrait-primary",
            "icons": [
              {
                "src": "https://via.placeholder.com/192x192/ff0a8c/ffffff?text=L",
                "sizes": "192x192",
                "type": "image/png"
              },
              {
                "src": "https://via.placeholder.com/512x512/ff0a8c/ffffff?text=L", 
                "sizes": "512x512",
                "type": "image/png"
              }
            ]
          }
          EOF
          
          # Criar service worker
          cat > sw.js << 'EOF'
          const CACHE_NAME = 'livelo-analytics-v1';
          const urlsToCache = [
            '/',
            '/index.html',
            '/manifest.json'
          ];
          
          self.addEventListener('install', (event) => {
            event.waitUntil(
              caches.open(CACHE_NAME)
                .then((cache) => cache.addAll(urlsToCache))
            );
          });
          
          self.addEventListener('fetch', (event) => {
            event.respondWith(
              caches.match(event.request)
                .then((response) => {
                  return response || fetch(event.request);
                })
            );
          });
          EOF
          
          # Criar firebase.json
          cat > firebase.json << 'EOF'
          {
            "hosting": {
              "public": "./public",
              "ignore": [
                "firebase.json",
                "**/.*",
                "**/node_modules/**"
              ],
              "rewrites": [
                {
                  "source": "**",
                  "destination": "/index.html"
                }
              ],
              "headers": [
                {
                  "source": "/sw.js",
                  "headers": [
                    {
                      "key": "Service-Worker-Allowed",
                      "value": "/"
                    }
                  ]
                }
              ]
            }
          }
          EOF
          
          echo "‚úÖ Arquivos PWA criados com sucesso!"
      
      # Configurar e publicar no GitHub Pages (MANTIDO)
      - name: Configurar diret√≥rio de publica√ß√£o
        run: |
          mkdir -p ./public
          
          # Copiar o arquivo HTML principal
          if [ -f "relatorio_livelo.html" ]; then
            cp relatorio_livelo.html ./public/index.html
            echo "‚úÖ HTML copiado para public/"
          else
            echo "‚ùå relatorio_livelo.html n√£o encontrado"
            # Criar HTML de emerg√™ncia
            cat > ./public/index.html << 'EOF'
          <!DOCTYPE html>
          <html>
          <head>
            <title>Livelo Analytics - Em Manuten√ß√£o</title>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <style>
              body { font-family: Arial; text-align: center; padding: 50px; background: #f8f9fa; }
              .container { max-width: 600px; margin: 0 auto; }
              .error { color: #dc3545; }
              .info { color: #6c757d; margin-top: 20px; }
            </style>
          </head>
          <body>
            <div class="container">
              <h1>üöß Livelo Analytics</h1>
              <p class="error">Dashboard temporariamente indispon√≠vel</p>
              <p class="info">O sistema est√° em manuten√ß√£o. Tente novamente em alguns minutos.</p>
              <p class="info"><small>√öltima tentativa: $(date)</small></p>
            </div>
          </body>
          </html>
          EOF
          fi
          
          # Copiar arquivos PWA
          cp manifest.json ./public/
          cp sw.js ./public/
          
          # Copiar outros arquivos necess√°rios
          cp -r *.css *.js ./public/ 2>/dev/null || echo "Nenhum arquivo CSS/JS adicional encontrado"
          if [ -d "relatorios" ]; then
            cp -r relatorios/* ./public/ 2>/dev/null || echo "Nenhum arquivo encontrado em relat√≥rios"
          fi
          
          echo "Arquivos no diret√≥rio public:"
          ls -la ./public/
          
      - name: Setup Pages
        uses: actions/configure-pages@v3
        
      - name: Deploy para GitHub Pages
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          folder: public
          branch: gh-pages
          clean: true
      
      # ============ DEPLOY FIREBASE (NOVO) ============
      
      - name: Instalar Firebase CLI
        run: npm install -g firebase-tools
      
      - name: Deploy para Firebase Hosting
        if: env.SCRAPING_FALHOU == 'false'  # S√≥ deploy se scraping funcionou
        run: |
          # Deploy usando token do secret
          echo '${{ secrets.FIREBASE_SERVICE_ACCOUNT }}' > firebase-key.json
          export GOOGLE_APPLICATION_CREDENTIALS="firebase-key.json"
          firebase deploy --project "$FIREBASE_PROJECT_ID" --only hosting
        env:
          FIREBASE_TOKEN: ${{ secrets.FIREBASE_TOKEN }}
          FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
      
      - name: Deploy de emerg√™ncia no Firebase (dados antigos)
        if: env.SCRAPING_FALHOU == 'true'  # Deploy mesmo com falha para manter site no ar
        run: |
          echo "‚ö†Ô∏è Fazendo deploy de emerg√™ncia com dados antigos..."
          firebase deploy --token "$FIREBASE_TOKEN" --project "$FIREBASE_PROJECT_ID" --only hosting
        env:
          FIREBASE_TOKEN: ${{ secrets.FIREBASE_TOKEN }}
          FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
        continue-on-error: true
      
      # ============ LOG FINAL ============
      
      - name: Resumo da execu√ß√£o
        run: |
          echo "
          üìä RESUMO DA EXECU√á√ÉO
          =====================
          ‚è∞ Hor√°rio: $(date)
          üìÅ Arquivos gerados: $(ls -la ./public/ | wc -l) arquivos
          üîç Status scraping: ${{ env.SCRAPING_FALHOU == 'true' && 'FALHOU' || 'SUCESSO' }}
          üåê GitHub Pages: ‚úÖ Deployado
          üî• Firebase: ${{ env.SCRAPING_FALHOU == 'true' && '‚ö†Ô∏è Deploy emerg√™ncia' || '‚úÖ Deploy normal' }}
          
          üìß Notifica√ß√µes: ${{ env.SCRAPING_FALHOU == 'true' && 'Issue criada - email enviado' || 'Nenhuma necess√°ria' }}
          "
          
          if [ "${{ env.SCRAPING_FALHOU }}" = "true" ]; then
            echo "::warning::Scraper falhou mas deploy foi mantido com dados antigos"
          else
            echo "::notice::Execu√ß√£o completada com sucesso!"
          fi
