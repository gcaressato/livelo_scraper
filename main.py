#!/usr/bin/env python3
"""
Main.py - Orquestrador do Sistema Livelo Analytics (VERS√ÉO SUPER ROBUSTA)
PRIORIDADE ABSOLUTA: Scraping ‚Üí An√°lise ‚Üí Deploy GitHub Pages
Firebase √© 100% opcional e n√£o pode interferir no pipeline principal
VALIDA√á√ÉO RIGOROSA: Falha imediatamente se dados insuficientes forem coletados
"""

import os
import sys
import subprocess
import argparse
from datetime import datetime
import logging
import traceback

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('main_livelo.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class LiveloOrchestrator:
    def __init__(self):
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.sucesso_etapas = {
            'scraping': False,
            'analise': False,
            'validacao': False,
            'deploy_preparacao': False
        }
        # Firebase √© completamente separado
        self.firebase_opcional = False
        
        # CONFIGURA√á√ïES CR√çTICAS DE VALIDA√á√ÉO
        self.MIN_PARCEIROS = 50  # N√∫mero m√≠nimo de parceiros esperados
        self.MIN_HTML_SIZE = 100000  # 100KB m√≠nimo para HTML
        self.MIN_EXCEL_SIZE = 5000   # 5KB m√≠nimo para Excel
        
    def validar_ambiente(self):
        """Valida se o ambiente est√° preparado"""
        logger.info("üîç Validando ambiente...")
        
        # Verificar arquivos cr√≠ticos
        arquivos_necessarios = ['livelo_scraper.py', 'livelo_reporter.py']
        for arquivo in arquivos_necessarios:
            if not os.path.exists(arquivo):
                logger.warning(f"‚ö†Ô∏è Arquivo n√£o encontrado: {arquivo}")
        
        # Verificar se Python tem os m√≥dulos necess√°rios
        try:
            import pandas
            import plotly
            logger.info("‚úÖ Depend√™ncias b√°sicas dispon√≠veis")
        except ImportError as e:
            logger.error(f"‚ùå Depend√™ncia ausente: {e}")
            return False
        
        return True
    
    def validar_dados_excel(self):
        """Valida√ß√£o RIGOROSA dos dados coletados no Excel"""
        logger.info("üîç Validando dados coletados (RIGOROSO)...")
        
        if not os.path.exists('livelo_parceiros.xlsx'):
            logger.error("‚ùå FALHA CR√çTICA: livelo_parceiros.xlsx n√£o encontrado")
            return False
        
        try:
            import pandas as pd
            
            # Ler o Excel
            df = pd.read_excel('livelo_parceiros.xlsx')
            num_registros = len(df)
            
            logger.info(f"üìä Registros encontrados: {num_registros}")
            
            # VALIDA√á√ÉO 1: N√∫mero m√≠nimo de registros
            if num_registros < self.MIN_PARCEIROS:
                logger.error(f"‚ùå FALHA CR√çTICA: Poucos dados coletados!")
                logger.error(f"   Coletados: {num_registros}")
                logger.error(f"   M√≠nimo esperado: {self.MIN_PARCEIROS}")
                logger.error("   Poss√≠veis causas:")
                logger.error("   ‚Ä¢ Mudan√ßa na estrutura do site")
                logger.error("   ‚Ä¢ Bloqueio por anti-bot")
                logger.error("   ‚Ä¢ Problemas de conectividade")
                logger.error("   ‚Ä¢ Erro no script de scraping")
                return False
            
            # VALIDA√á√ÉO 2: Verificar se h√° colunas essenciais
            colunas_essenciais = ['nome', 'categoria']  # Ajustar conforme sua estrutura
            colunas_encontradas = df.columns.tolist()
            
            for coluna in colunas_essenciais:
                # Busca flex√≠vel por colunas (case insensitive)
                encontrou = any(coluna.lower() in col.lower() for col in colunas_encontradas)
                if not encontrou:
                    logger.warning(f"‚ö†Ô∏è Coluna esperada n√£o encontrada: {coluna}")
            
            # VALIDA√á√ÉO 3: Verificar se dados n√£o est√£o vazios
            dados_vazios = df.isnull().all(axis=1).sum()
            if dados_vazios > (num_registros * 0.5):  # Mais de 50% vazios
                logger.error(f"‚ùå FALHA CR√çTICA: Muitos registros vazios ({dados_vazios}/{num_registros})")
                return False
            
            # VALIDA√á√ÉO 4: Verificar diversidade de dados (n√£o todos iguais)
            if len(df.columns) > 0:
                primeira_coluna = df.iloc[:, 0]
                valores_unicos = primeira_coluna.nunique()
                if valores_unicos < 3:  # Menos de 3 valores √∫nicos √© suspeito
                    logger.warning(f"‚ö†Ô∏è Pouca diversidade nos dados: {valores_unicos} valores √∫nicos")
            
            logger.info(f"‚úÖ Dados validados: {num_registros} parceiros coletados")
            logger.info(f"‚úÖ Colunas encontradas: {len(colunas_encontradas)}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå FALHA CR√çTICA: Erro ao validar Excel: {e}")
            logger.error(f"Trace: {traceback.format_exc()}")
            return False
        
   def validar_arquivos_gerados(self):
        """Valida se os arquivos foram gerados corretamente com crit√©rios RIGOROSOS"""
        logger.info("üîç Validando arquivos gerados (RIGOROSO)...")
        
        # ‚úÖ CORRE√á√ÉO: Validar arquivos onde realmente est√£o
        arquivos_criticos = {
            'public/index.html': self.MIN_HTML_SIZE,  # HTML no public/
            'livelo_parceiros.xlsx': self.MIN_EXCEL_SIZE  # Excel na raiz
        }
        
        for arquivo, tamanho_min in arquivos_criticos.items():
            if not os.path.exists(arquivo):
                logger.error(f"‚ùå FALHA CR√çTICA: Arquivo n√£o encontrado: {arquivo}")
                return False
            
            size = os.path.getsize(arquivo)
            if size < tamanho_min:
                logger.error(f"‚ùå FALHA CR√çTICA: {arquivo} muito pequeno!")
                logger.error(f"   Tamanho atual: {size:,} bytes")
                logger.error(f"   M√≠nimo esperado: {tamanho_min:,} bytes")
                logger.error("   Indica falha no processo de gera√ß√£o")
                return False
            
            logger.info(f"‚úÖ {arquivo}: {size:,} bytes")
        
        # VALIDA√á√ÉO 2: Dados do Excel (CR√çTICA)
        if not self.validar_dados_excel():
            logger.error("‚ùå FALHA CR√çTICA: Valida√ß√£o de dados falhou")
            return False
        
        # ‚úÖ CORRE√á√ÉO: Validar HTML onde realmente est√°
        try:
            with open('public/index.html', 'r', encoding='utf-8') as f:
                conteudo = f.read()
                
                # Verifica√ß√µes obrigat√≥rias
                verificacoes_criticas = [
                    ('</html>', 'HTML bem formado'),
                    ('Livelo', 'conte√∫do relacionado ao Livelo'),
                    ('table', 'tabelas de dados'),
                ]
                
                for busca, desc in verificacoes_criticas:
                    if busca not in conteudo:
                        logger.error(f"‚ùå FALHA CR√çTICA: HTML n√£o cont√©m {desc}")
                        return False
                
                # Verificar se n√£o √© uma p√°gina de erro
                indicadores_erro = [
                    'erro 404', '404 not found', 'p√°gina n√£o encontrada',
                    'access denied', 'blocked', 'captcha',
                    'erro 500', 'internal server error'
                ]
                
                conteudo_lower = conteudo.lower()
                for indicador in indicadores_erro:
                    if indicador in conteudo_lower:
                        logger.error(f"‚ùå FALHA CR√çTICA: HTML indica erro: '{indicador}'")
                        return False
                
                # Verificar tamanho m√≠nimo do conte√∫do
                if len(conteudo) < self.MIN_HTML_SIZE:
                    logger.error(f"‚ùå FALHA CR√çTICA: HTML muito pequeno!")
                    logger.error(f"   Tamanho: {len(conteudo):,} caracteres")
                    logger.error(f"   M√≠nimo: {self.MIN_HTML_SIZE:,} caracteres")
                    return False
                
                logger.info(f"‚úÖ HTML validado: {len(conteudo):,} caracteres")
                
        except Exception as e:
            logger.error(f"‚ùå FALHA CR√çTICA: Erro ao validar HTML: {e}")
            return False
            
        self.sucesso_etapas['validacao'] = True
        return True
        
    def executar_scraping(self):
        """Executa o scraping do site Livelo"""
        logger.info("üï∑Ô∏è Iniciando scraping...")
        
        try:
            # Verificar se o scraper existe
            if not os.path.exists('livelo_scraper.py'):
                logger.warning("‚ö†Ô∏è livelo_scraper.py n√£o encontrado")
                
                # Verificar se dados j√° existem E s√£o v√°lidos
                if os.path.exists('livelo_parceiros.xlsx'):
                    logger.info("‚ÑπÔ∏è Tentando usar dados existentes...")
                    if self.validar_dados_excel():
                        logger.info("‚úÖ Usando dados existentes v√°lidos")
                        self.sucesso_etapas['scraping'] = True
                        return True
                    else:
                        logger.error("‚ùå Dados existentes s√£o inv√°lidos")
                        return False
                else:
                    logger.error("‚ùå Scraper ausente e sem dados")
                    return False
            
            # Executar scraper com timeout mais longo
            logger.info("üìä Executando scraper...")
            resultado = subprocess.run([
                sys.executable, 'livelo_scraper.py'
            ], capture_output=True, text=True, timeout=1800)  # 30 min
            
            if resultado.returncode == 0:
                logger.info("‚úÖ Scraper executado sem erros")
                
                # VALIDA√á√ÉO IMEDIATA: Verificar se arquivo foi gerado E √© v√°lido
                if os.path.exists('livelo_parceiros.xlsx'):
                    size = os.path.getsize('livelo_parceiros.xlsx')
                    logger.info(f"üìÑ livelo_parceiros.xlsx: {size:,} bytes")
                    
                    # Validar os dados imediatamente
                    if self.validar_dados_excel():
                        logger.info("‚úÖ Scraping conclu√≠do com dados v√°lidos")
                        self.sucesso_etapas['scraping'] = True
                        return True
                    else:
                        logger.error("‚ùå FALHA CR√çTICA: Scraper gerou dados inv√°lidos")
                        return False
                else:
                    logger.error("‚ùå FALHA CR√çTICA: Scraper executou mas n√£o gerou arquivo")
                    return False
            else:
                logger.error(f"‚ùå FALHA CR√çTICA: Scraper falhou (c√≥digo {resultado.returncode})")
                if resultado.stderr:
                    logger.error(f"Erro: {resultado.stderr[:500]}")
                if resultado.stdout:
                    logger.info(f"Output: {resultado.stdout[-500:]}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("‚ùå FALHA CR√çTICA: Timeout no scraping (30 minutos)")
            return False
        except Exception as e:
            logger.error(f"‚ùå FALHA CR√çTICA: Erro inesperado no scraping: {e}")
            logger.error(f"Trace: {traceback.format_exc()}")
            return False
    
    def executar_analise(self):
            """Executa a an√°lise e gera√ß√£o do relat√≥rio"""
            logger.info("üìä Iniciando an√°lise...")
            
            try:
                # Verificar se o arquivo de dados existe E √© v√°lido
                if not os.path.exists('livelo_parceiros.xlsx'):
                    logger.error("‚ùå FALHA CR√çTICA: livelo_parceiros.xlsx n√£o encontrado para an√°lise")
                    return False
                
                # Validar dados antes da an√°lise
                if not self.validar_dados_excel():
                    logger.error("‚ùå FALHA CR√çTICA: Dados inv√°lidos para an√°lise")
                    return False
                
                # Verificar se o reporter existe
                if not os.path.exists('livelo_reporter.py'):
                    logger.error("‚ùå FALHA CR√çTICA: livelo_reporter.py n√£o encontrado")
                    return False
                
                logger.info("üìà Executando an√°lise com reporter...")
                resultado = subprocess.run([
                    sys.executable, 'livelo_reporter.py', 'livelo_parceiros.xlsx'
                ], capture_output=True, text=True, timeout=600)  # 10 min
                
                if resultado.returncode == 0:
                    logger.info("‚úÖ Reporter executado sem erros")
                    
                    # ‚úÖ CORRE√á√ÉO: Verificar arquivo onde realmente √© gerado
                    if not os.path.exists('public/index.html'):
                        logger.error("‚ùå FALHA CR√çTICA: Reporter n√£o gerou public/index.html")
                        return False
                    
                    size = os.path.getsize('public/index.html')
                    logger.info(f"üìÑ public/index.html: {size:,} bytes")
                    
                    self.sucesso_etapas['analise'] = True
                    
                    # Executar valida√ß√£o completa imediatamente
                    if self.validar_arquivos_gerados():
                        logger.info("‚úÖ An√°lise conclu√≠da com arquivos v√°lidos")
                        return True
                    else:
                        logger.error("‚ùå FALHA CR√çTICA: An√°lise gerou arquivos inv√°lidos")
                        return False
                    
                else:
                    logger.error(f"‚ùå FALHA CR√çTICA: Reporter falhou (c√≥digo {resultado.returncode})")
                    if resultado.stderr:
                        logger.error(f"Erro: {resultado.stderr[:500]}")
                    if resultado.stdout:
                        logger.info(f"Output: {resultado.stdout[-500:]}")
                    return False
                    
            except subprocess.TimeoutExpired:
                logger.error("‚ùå FALHA CR√çTICA: Timeout na an√°lise (10 minutos)")
                return False
            except Exception as e:
                logger.error(f"‚ùå FALHA CR√çTICA: Erro inesperado na an√°lise: {e}")
                logger.error(f"Trace: {traceback.format_exc()}")
                return False
    
    def preparar_deploy_github(self):
        """Prepara arquivos para GitHub Pages - Arquivos j√° est√£o no local correto"""
        logger.info("üöÄ Verificando arquivos para GitHub Pages...")
        
        try:
            # Criar diret√≥rio public se n√£o existir (mas j√° deve existir)
            if not os.path.exists('public'):
                logger.error("‚ùå FALHA CR√çTICA: Diret√≥rio public/ n√£o existe")
                return False
            
            # ‚úÖ CORRE√á√ÉO: Apenas copiar o Excel para o public/
            if os.path.exists('livelo_parceiros.xlsx'):
                import shutil
                shutil.copy2('livelo_parceiros.xlsx', 'public/livelo_parceiros.xlsx')
                logger.info("üìÑ livelo_parceiros.xlsx ‚Üí public/livelo_parceiros.xlsx")
            else:
                logger.error("‚ùå FALHA CR√çTICA: livelo_parceiros.xlsx n√£o encontrado")
                return False
            
            # Verificar se arquivos finais est√£o prontos para deploy
            arquivos_verificar = [
                ('public/index.html', self.MIN_HTML_SIZE),
                ('public/livelo_parceiros.xlsx', self.MIN_EXCEL_SIZE)
            ]
            
            for arquivo, tamanho_min in arquivos_verificar:
                if os.path.exists(arquivo):
                    size = os.path.getsize(arquivo)
                    if size < tamanho_min:
                        logger.error(f"‚ùå FALHA CR√çTICA: {arquivo} muito pequeno para deploy: {size:,} bytes")
                        return False
                    logger.info(f"‚úÖ {arquivo}: {size:,} bytes")
                else:
                    logger.error(f"‚ùå FALHA CR√çTICA: {arquivo} n√£o foi preparado")
                    return False
            
            logger.info("‚úÖ Todos os arquivos prontos para deploy no public/")
            self.sucesso_etapas['deploy_preparacao'] = True
            return True
            
        except Exception as e:
            logger.error(f"‚ùå FALHA CR√çTICA: Erro na prepara√ß√£o do deploy: {e}")
            logger.error(f"Trace: {traceback.format_exc()}")
            return False
    
    def tentar_firebase_opcional(self):
        """Tenta configurar Firebase APENAS se tudo estiver OK (100% opcional)"""
        logger.info("üî• Verificando Firebase (opcional)...")
        
        try:
            # S√≥ tentar se as etapas cr√≠ticas foram bem-sucedidas
            if not all([self.sucesso_etapas['scraping'], 
                       self.sucesso_etapas['analise'], 
                       self.sucesso_etapas['validacao'],
                       self.sucesso_etapas['deploy_preparacao']]):
                logger.info("‚è≠Ô∏è Pulando Firebase - etapas principais ainda n√£o conclu√≠das")
                return False
            
            # Verificar configura√ß√£o b√°sica
            firebase_project = os.getenv('FIREBASE_PROJECT_ID')
            firebase_account = os.getenv('FIREBASE_SERVICE_ACCOUNT')
            
            if not firebase_project or not firebase_account:
                logger.info("‚ÑπÔ∏è Firebase n√£o configurado (normal)")
                logger.info("üí° Sistema funciona 100% sem Firebase")
                return False
            
            # Se chegou at√© aqui, Firebase est√° configurado
            logger.info(f"üî• Firebase detectado: {firebase_project}")
            
            # Tentar executar notifica√ß√µes
            if os.path.exists('notification_sender.py'):
                logger.info("üì± Executando notifica√ß√µes Firebase...")
                resultado = subprocess.run([
                    sys.executable, 'notification_sender.py'
                ], capture_output=True, text=True, timeout=180)  # 3 min
                
                if resultado.returncode == 0:
                    logger.info("‚úÖ Notifica√ß√µes Firebase funcionando")
                    self.firebase_opcional = True
                    return True
                else:
                    logger.warning("‚ö†Ô∏è Notifica√ß√µes com problemas (n√£o afeta sistema)")
                    return False
            else:
                logger.info("‚ÑπÔ∏è notification_sender.py n√£o encontrado")
                return False
                
        except subprocess.TimeoutExpired:
            logger.warning("‚ö†Ô∏è Timeout no Firebase (n√£o cr√≠tico)")
            return False
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Firebase com problemas (n√£o cr√≠tico): {e}")
            return False
    
    def gerar_relatorio_execucao(self):
        """Gera relat√≥rio final da execu√ß√£o"""
        logger.info("üìã Gerando relat√≥rio de execu√ß√£o...")
        
        # Contar apenas etapas cr√≠ticas
        etapas_criticas = ['scraping', 'analise', 'validacao', 'deploy_preparacao']
        criticas_sucesso = sum(self.sucesso_etapas[etapa] for etapa in etapas_criticas)
        total_criticas = len(etapas_criticas)
        
        print("\n" + "="*70)
        print("üìä RELAT√ìRIO DE EXECU√á√ÉO LIVELO ANALYTICS")
        print("="*70)
        print(f"‚è∞ Timestamp: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        print(f"üî• Etapas Cr√≠ticas: {criticas_sucesso}/{total_criticas}")
        print(f"üî• Firebase Opcional: {'‚úÖ Ativo' if self.firebase_opcional else '‚ÑπÔ∏è Desabilitado'}")
        print("")
        print("üéØ PIPELINE PRINCIPAL (CR√çTICO):")
        
        status_icons = {
            'scraping': 'üï∑Ô∏è',
            'analise': 'üìä', 
            'validacao': 'üîç',
            'deploy_preparacao': 'üöÄ'
        }
        
        for etapa in etapas_criticas:
            sucesso = self.sucesso_etapas[etapa]
            icon = status_icons.get(etapa, '‚öôÔ∏è')
            status = '‚úÖ SUCESSO' if sucesso else '‚ùå FALHA'
            print(f"   {icon} {etapa.replace('_', ' ').title()}: {status}")
        
        print("")
        print("üìÅ ARQUIVOS PRINCIPAIS:")
        
        # Verificar arquivos cr√≠ticos
        arquivos_criticos = [
            'relatorio_livelo.html',
            'livelo_parceiros.xlsx',
            'public/index.html'
        ]
        
        for arquivo in arquivos_criticos:
            if os.path.exists(arquivo):
                size = os.path.getsize(arquivo)
                print(f"   üìÑ {arquivo}: {size:,} bytes")
            else:
                print(f"   ‚ùå {arquivo}: N√ÉO ENCONTRADO")
        
        # Status final baseado APENAS em etapas cr√≠ticas
        print("")
        if criticas_sucesso >= total_criticas:
            print("üéâ PIPELINE PRINCIPAL CONCLU√çDO COM SUCESSO!")
            print("")
            print("üåê ACESSO AO SISTEMA:")
            print("   ‚úÖ GitHub Pages: https://gcaressato.github.io/livelo_scraper/")
            if self.firebase_opcional:
                print("   üî• Firebase: https://livel-analytics.web.app/")
            
            print("")
            print("‚ú® FUNCIONALIDADES ATIVAS:")
            print("   ‚úÖ Dados coletados e processados")
            print("   ‚úÖ Dashboard HTML responsivo")
            print("   ‚úÖ Arquivos preparados para deploy")
            print("   ‚úÖ Sistema 100% funcional")
            
            if not self.firebase_opcional:
                print("   ‚ÑπÔ∏è Firebase desabilitado (opcional)")
            
            status_final = True
            
        else:
            print("‚ùå FALHAS NO PIPELINE PRINCIPAL!")
            print("")
            print("üîß PROBLEMAS DETECTADOS:")
            
            for etapa in etapas_criticas:
                if not self.sucesso_etapas[etapa]:
                    print(f"   ‚ùå {etapa.replace('_', ' ').title()} falhou")
            
            print("")
            print("üí° A√á√ïES RECOMENDADAS:")
            print("   1. Verificar logs detalhados")
            print("   2. Testar scraper individualmente")
            print("   3. Verificar depend√™ncias Python")
            print("   4. Checar conectividade de rede")
            print("   5. Verificar se site mudou estrutura")
            
            status_final = False
        
        print("="*70)
        
        return status_final
    
    def executar_pipeline_principal(self, pular_scraping=False, apenas_analise=False):
        """Executa o pipeline principal (sem Firebase) com foco total na robustez"""
        print("\nüöÄ INICIANDO PIPELINE LIVELO ANALYTICS")
        print("="*60)
        print(f"‚è∞ Timestamp: {self.timestamp}")
        print(f"üìÅ Diret√≥rio: {os.getcwd()}")
        print(f"üêç Python: {sys.version.split()[0]}")
        print("")
        print("üéØ FOCO: Pipeline principal (Scraping ‚Üí An√°lise ‚Üí Deploy)")
        print("üî• Firebase √© 100% opcional e n√£o interfere no processo")
        print(f"üìä Valida√ß√£o rigorosa: min {self.MIN_PARCEIROS} parceiros")
        print("="*60)
        
        try:
            # 0. VALIDAR AMBIENTE
            logger.info("üîç Etapa 1/4: Validando ambiente...")
            if not self.validar_ambiente():
                logger.error("‚ùå FALHA CR√çTICA: Ambiente n√£o est√° preparado")
                return False
            
            # 1. SCRAPING
            if not pular_scraping and not apenas_analise:
                logger.info("üï∑Ô∏è Etapa 2/4: Executando scraping...")
                if not self.executar_scraping():
                    logger.error("‚ùå FALHA CR√çTICA: Scraping falhou")
                    return False
            else:
                logger.info("‚è≠Ô∏è Etapa 2/4: Pulando scraping...")
                if os.path.exists('livelo_parceiros.xlsx'):
                    if self.validar_dados_excel():
                        logger.info("‚úÖ Usando dados existentes v√°lidos")
                        self.sucesso_etapas['scraping'] = True
                    else:
                        logger.error("‚ùå FALHA CR√çTICA: Dados existentes s√£o inv√°lidos")
                        return False
                else:
                    logger.error("‚ùå FALHA CR√çTICA: Sem dados para an√°lise")
                    return False
            
            # 2. AN√ÅLISE + VALIDA√á√ÉO
            logger.info("üìä Etapa 3/4: Executando an√°lise...")
            if not self.executar_analise():
                logger.error("‚ùå FALHA CR√çTICA: An√°lise falhou")
                return False
            
            # 3. PREPARAR DEPLOY
            if not apenas_analise:
                logger.info("üöÄ Etapa 4/4: Preparando deploy...")
                if not self.preparar_deploy_github():
                    logger.error("‚ùå FALHA CR√çTICA: Prepara√ß√£o do deploy falhou")
                    return False
            else:
                logger.info("‚è≠Ô∏è Etapa 4/4: Pulando prepara√ß√£o deploy...")
                self.sucesso_etapas['deploy_preparacao'] = True
            
            # PIPELINE PRINCIPAL CONCLU√çDO COM SUCESSO
            logger.info("üéâ Pipeline principal conclu√≠do com 100% de sucesso!")
            
            # 4. FIREBASE (OPCIONAL - N√ÉO PODE AFETAR O RESULTADO)
            if not apenas_analise:
                logger.info("üî• Extra: Tentando Firebase (opcional)...")
                try:
                    self.tentar_firebase_opcional()
                    logger.info("‚úÖ Verifica√ß√£o Firebase conclu√≠da")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Firebase com problemas (ignorado): {e}")
            
            # 5. RELAT√ìRIO FINAL
            return self.gerar_relatorio_execucao()
            
        except KeyboardInterrupt:
            logger.info("‚ö†Ô∏è Execu√ß√£o interrompida pelo usu√°rio")
            return False
        except Exception as e:
            logger.error(f"‚ùå FALHA CR√çTICA: Erro inesperado no pipeline: {e}")
            logger.error(f"Trace: {traceback.format_exc()}")
            return False

def main():
    parser = argparse.ArgumentParser(description='Livelo Analytics - Sistema Robusto')
    parser.add_argument('--pular-scraping', action='store_true', 
                       help='Pular etapa de scraping (usar dados existentes)')
    parser.add_argument('--apenas-analise', action='store_true',
                       help='Executar apenas an√°lise e relat√≥rio')
    parser.add_argument('--debug', action='store_true',
                       help='Ativar modo debug com mais logs')
    parser.add_argument('--min-parceiros', type=int, default=50,
                       help='N√∫mero m√≠nimo de parceiros para considerar sucesso')
    
    args = parser.parse_args()
    
    # Configurar n√≠vel de log
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
        logger.info("üêõ Modo debug ativado")
    
    orchestrator = LiveloOrchestrator()
    
    # Aplicar configura√ß√£o personalizada
    if args.min_parceiros:
        orchestrator.MIN_PARCEIROS = args.min_parceiros
        logger.info(f"üéØ M√≠nimo de parceiros ajustado para: {args.min_parceiros}")
    
    # Executar pipeline principal
    logger.info("üéØ Iniciando pipeline principal...")
    sucesso = orchestrator.executar_pipeline_principal(
        pular_scraping=args.pular_scraping,
        apenas_analise=args.apenas_analise
    )
    
    # Resultado final
    if sucesso:
        logger.info("üéâ Sistema Livelo Analytics funcionando perfeitamente!")
        print("\nüöÄ SISTEMA PRONTO PARA USO!")
        print("üì± Acesse: https://gcaressato.github.io/livelo_scraper/")
        sys.exit(0)
    else:
        logger.error("‚ùå FALHA CR√çTICA: Pipeline falhou!")
        print("\nüí• SISTEMA COM FALHAS CR√çTICAS!")
        print("üìß Notifica√ß√£o de erro ser√° enviada pelo GitHub")
        sys.exit(1)  # FALHA EXPL√çCITA

if __name__ == "__main__":
    main()
